---
title: "Final Project"
author: "Jess White"
date: "4/14/2020"
output: 
  html_document: 
    toc: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

fastq_to_fasta -n -i ERR164585.Unmapped.out.mate2 -o ERR164585.Unmapped.out.mate2.fasta



**1. Download at least one FASTQ file that you will be working with for your project. Document the following details: (2pt)**

+ **where did you get it from?**
https://www.ebi.ac.uk/ena/data/view/ERS167310
+ **what publication is it linked to?**
[Seo et al., *Genome Research*, 2012.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3483540/pdf/2109.pdf)
+ **who generated the data?**
South Korean researchers from Seoul National University and The Catholic University of Korea
+ **how was the DNA extracted?**
RNAs were extracted from tissue using RNAiso Plus (Takara Bio Inc.), followed by purification using RNeasy MinElute (Qiagen Inc.). RNAs were assessed for quality and was quantified using an RNA 6000 Nano LabChip on a 2100 Bioanalyzer (Agilent Inc.).
+ **what library prep was used?**
All that is mentioned is that the libraries were prepared per protocol described in [Ju et al., *Nature Genetics*, 2011](https://www.nature.com/articles/ng.872).  In that paper, Illumina sequencing libraries were constructed for paired-end sequencing (with an insert size of ~500 bp) but no additional detail was provided on how the library was constructed.
+ **what cell type was used?**
Human lung cancer tumor biopsies with paired normal surrounding tissue
+ **what was the treatment/experimental condition?**
No treatment/experimental condition were used but biopsies of the tumor were matched with paired normal surrounding tissue.
+ **what sequencing platform was used?**
Illumina HiSeq 2000

**2. Align the FASTQ file with an appropriate aligner (you may have to build a new index). Document: (3pt)**

+ **parameters (and why you chose them)**
+ **summary of outcome and basic QC**

# Alignment

## STAR

I created an index with the hg38 genome using the following commands.

```{}
wget http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz
gunzip hg38.fa.gz
wget http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/genes/hg38.ensGene.gtf.gz
gunzip hg38.ensGene.gtf.gz
mkdir hg38_STARindex

STAR -- runMode genomeGenerate \
     -- runThreadN 8 \
     -- genomeDir hg38_STARindex \ 
     -- genomeFastaFiles hg38.fa \
     -- sjdbGTFfile hg38.ensGene.gtf
```

I downloaded and organized the relevant files using the below commands.

```{}
wget -O experiment_list.txt 'https://www.ebi.ac.uk/ena/data/warehouse/filereport?accession=PRJEB2784&result=read_run&fields=study_accession,sample_accession,secondary_sample_accession,experiment_accession,run_accession,fastq_ftp&download=txt'
egrep "ERR" experiment_list.txt | cut -f 5 > ERR_list.txt
cut -f 6 experiment_list.txt | egrep "ftp" > ftp_links.txt

# create one directory per each sample and check number of folders in wd
for recs in `cat ERR_list.txt`; 
  do mkdir ${recs};
done
ls -l | grep "^d" | wc -l

# looking at the experiment_list.txt file, there are 5 run_accessions without associated FASTQ files
rmdir ERR062334 ERR062335 ERR062336 ERR062337 ERR062338

# then used text editor to remove those 5 files from the ERR_list.txt
vi ERR_list.txt

# paired end reads in separate FASTQ files
cat ftp_links.txt | grep -o "^.*;" | sed 's/.$//' > ftp_1.txt
cat ftp_links.txt | egrep ";" | sed 's/^.*;//' > ftp_2.txt

for recs in `cat ERR_list.txt`;
  do for links in `cat ftp_1.txt`;
    do wget -P `pwd`/${recs}/ ftp://${links};
  done;
done

for recs in `cat ERR_list.txt`;
  do for links in `cat ftp_2.txt`;
    do wget -P `pwd`/${recs}/ ftp://${links};
  done;
done
```

I wrote a script to run STAR aligner with paired end reads in separate FASTQ files.  I also altered some of the basic parameters, including:

 + `--outFilterMultimapNmax 20` to better align with ENCODE RNA-seq guidelines
 + `--alignSJoverhangMin 8` to better align with ENCODE RNA-seq guidelines
 + `-- alignIntronMin 10` as Luce mentioned in class, this default is considered not well chosen, so I reduced the minimum intron length to be more permissive

```{}
#! / bin / bash

# Usage : star.sh <fastq_file_1> <fastq_file_2> <genref_dir> <alignment_dir>
# Check that we have our command line argument (s)

if [ "$#" -ne 4 ]; then
    echo "You must enter exactly 2 command line arguments"
    exit
fi

# Read argument from command line
# check that necessary files and directories exist

FILE1=$1
FILE2=$2
REF_DIR=$3
ALIGN_DIR=$4

if [[ ! -f $FILE1 ]]; then
    echo "$FILE1 does not exist . Exiting ... ";
    exit
else
    echo "$FILE1 exists ..."
fi


if [[ ! -f $FILE2 ]]; then
    echo "$FILE2 does not exist . Exiting ... ";
    exit
else
    echo "$FILE2 exists ..."
fi


#check to see if reference genome directory exist
if [[ ! -d $REF_DIR ]]; then
    echo "Reference genome directory does not exist . Exiting ... "
    exit
else
    echo "Reference genome directory exists ..."
fi


#check to see if alignment output directory exist
if [[ ! -d $ALIGN_DIR ]]; then
    echo "Alignment output directory does not exist . Exiting ... "
    exit
else
    echo "Alignment output directory exists ..."
fi


# Load packages that we will need
spack load star@2.7.0e
spack load samtools@1.9% gcc@6.3.0

f1="$(basename -- $FILE1)"
F1="${f1%.fastq.gz}"

f2="$(basename -- $FILE2)"
F2="${f2%.fastq.gz}"

FCOMBO="${F1%_1}"


# Run STAR , if result not already present
if [ ! -r ${WORKING_DIRECTORY}/${F1}.Aligned.sortedByCoord.out.bam ]; then
    STAR --runMode alignReads \
         --genomeDir ${REF_DIR} \
         --readFilesIn ${FILE1} ${FILE2} \
         --readFilesCommand zcat \
         --alignIntronMin 10 \
         --outFilterMultimapNmax 20 \
         --alignSJoverhangMin 8 \
         --outFileNamePrefix ${ALIGN_DIR}/${FCOMBO}. \
         --outSAMtype BAM SortedByCoordinate
fi


# Samtools index on BAM file
if [ -r ${ALIGN_DIR}/${F1}.Aligned.sortedByCoord.out.bam ]; then
    samtools index ${ALIGN_DIR}/${F1}.Aligned.sortedByCoord.out.bam
fi

if [ -r ${ALIGN_DIR}/${F2}.Aligned.sortedByCoord.out.bam ]; then
    samtools index ${ALIGN_DIR}/${F2}.Aligned.sortedByCoord.out.bam
fi

exit
```

```{}
bash star.sh fastq/ERR164473/ERR164473_1.fastq.gz fastq/ERR164473/ERR164473_2.fastq.gz hg38_STARindex/ alignment/
cp ERR164473Aligned.sortedByCoord.out_bamqc.html /home/jwh4001/
pscp jwh4001@aristotle.med.cornell.edu:/home/jwh4001/ERR164473.star.sorted_bamqc.html OneDrive/MS-CB/ANGSD/Project
```

I chose to use STAR instead of BWA given that this is RNA-seq data that will likely contain splice sites.  This was a good decision because 86.228% of sequences were primarily aligned and 23.726% contained splice sequences.  According to the BamQC report, this data set passed the Basic Statistics, Genome Coverage, Chromosome Read Density, Soft Clip Length Distributions, Indel Frequencies, and Mapping Quality Distribution QC tests.  However, the data set seemed to fail the Insert Length Distribution test.  I'm not sure what the distribution should generally look like, but it's heavily skewed towards the lower side with the greatest frequency of insertions <1990 bp.

# GitHub Repo

**1. Set up a github repository where you will store all your scripts, and ideally, even your report at one point. Send us the link to the repo. If you want to set your repo to private, you will have to grant us access, i.e. Friederike (friedue), Luce (lskrbnek), Merv (mfansler).**

On github, I created an [ANGSD repo](https://github.com/jessicaw9910/ANGSD) without a `README` file.  I already had git initialized in my local ANGSD directory, so I used the following commands to link the local directory to the github repo.

```{}
cd OneDrive/MS-CB/ANGSD
git add .
git commit -m "commit with full folder"
git remote add origin https://github.com/jessicaw9910/ANGSD.git
git remote -v
git push origin master
```

# Alignment

Additionally, I had not downloaded the annotation file previously, so I did that, as well.

```{}
cd ..
wget ftp://ftp.ensembl.org/pub/release-99/gtf/homo_sapiens/Homo_sapiens.GRCh38.99.gtf.gz -O hg38.99.gtf.gz
```

Per Merv's feedback, I altered the STAR code to run a 2-pass alignment rather than a 1-pass.  To do so, I put the initial alignment output in `alignment_1` and did not output a SAM/BAM file (`--outSAMtype None`).  Then I ran STAR again with the alignment output in `alignment_2` and added the option `--sjdbFileChrStartEnd ${ALIGN_DIR_1}/${recs}.SJ.out.tab`.

Using the following partition, `srun -n 4 --pty --partition=angsd_class --mem=50G bash -i`, it took at least an hour to run each sample.  Therefore, it will take at least a week to run all 169 samples via batch queuing.  Can you please confirm that the 2-pass approach I've implemented is correct and advise if increasing memory beyond the 50G in the batch queue script would be appropriate?  I attempted to run on more than 1 thread previously, but was informed that batch queue scripts can only access 1 thread.  I have not attempted to access more than 100G of the partition for any task to date.

[TO COME]

Updated STAR alignment batch script (`STAR_updated.sh`)

```{}
#!/bin/bash -l

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --job-name="STAR_alignment"
#SBATCH --time=24:0:00 # HH/MM/SS
#SBATCH --mem=50G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=jwh4001@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue

# Usage: sbatch star_updated.sh <ERR> <genref_dir> <alignment_dir>


# Check that we have our command line arguments
if [ "$#" -ne 3 ]; then
    echo "You must enter exactly 3 command line arguments: <ERR> <generef_dir> $
    exit
fi


# Read argument from command line
ERR=$1
REF_DIR=$2
ALIGN_DIR=$3


# check to see if reference genome directory exist
if [[ ! -d $REF_DIR ]]; then
    echo "Reference genome directory does not exist. Exiting... "
    exit
else
    echo "Reference genome directory exists..."
fi


# check to see if alignment output directory exist
if [[ ! -d $ALIGN_DIR ]]; then
    echo "Alignment output directory does not exist. Exiting... "
    exit
else
    echo "Alignment output directory exists..."
fi


# Load packages that we will need
spack load star@2.7.0e
spack load samtools@1.9% gcc@6.3.0


FILE1=/athena/angsd/scratch/jwh4001/project/fastq/${ERR}/${ERR}_1.fastq.gz
FILE2=/athena/angsd/scratch/jwh4001/project/fastq/${ERR}/${ERR}_2.fastq.gz

if [[ ! -f $FILE1 ]]; then
    echo "$FILE1 does not exist. Exiting...";
    exit
else
    echo "$FILE1 exists..."
if [[ ! -f $FILE2 ]]; then
    echo "$FILE2 does not exist. Exiting...";
    exit
else
    echo "$FILE2 exists..."
fi


# Run 2-pass STAR, if result not already present
if [ ! -r ${ALIGN_DIR}/${ERR}.Aligned.sortedByCoord.out.bam ]; then
    STAR --runMode alignReads \
         --runThreadN 4 \
         --genomeDir ${REF_DIR} \
         --readFilesIn ${FILE1} ${FILE2} \
         --readFilesCommand zcat \
         --twopassMode Basic \
         --alignIntronMin 10 \
         --outFilterMultimapNmax 20 \
         --alignSJoverhangMin 8 \
         --outFileNamePrefix ${ALIGN_DIR}/${ERR}. \
         --outSAMtype BAM SortedByCoordinate
fi

# Samtools index on BAM file if index file doesn't already exist
if [ ! -r ${ALIGN_DIR}/${ERR}.Aligned.sortedByCoord.out.bam.bai ]; then
    samtools index ${ALIGN_DIR}/${ERR}.Aligned.sortedByCoord.out.bam
else
    echo "${ALIGN_DIR}/${ERR}.Aligned.sortedByCoord.out.bam.bai already exists..."
fi

exit
```

New batch script to run new STAR alignment script for all ERR entries (`queue_star.sh`)

```{}
#!/bin/bash -l

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --job-name="batch_STAR"
#SBATCH --time=24:0:00 # HH/MM/SS
#SBATCH --mem=1G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=jwh4001@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue

# Usage: sbatch queue_star.sh <ERR_list>


# Check that we have our command line arguments
if [ "$#" -ne 1 ]; then
    echo "You must enter exactly 1 command line arguments: <ERR_list>"
    exit
fi


# Read argument from command line
ERR_FILE=$1

# check to see if ERR list exists
if [[ ! -r $ERR_FILE ]]; then
    echo "ERR file does not exist. Exiting... "
    exit
else
    echo "ERR file exists..."
fi


REF_DIR=/athena/angsd/scratch/jwh4001/project/hg38_STARindex/
ALIGN_DIR=/athena/angsd/scratch/jwh4001/project/alignment/


for ERR in `cat $ERR_FILE`;
    do
    if [ ! -r ${ALIGN_DIR}/${ERR}.Aligned.sortedByCoord.out.bam ]; then
        sbatch star_updated.sh ${ERR} ${REF_DIR} ${ALIGN_DIR}
    else
        echo "${ALIGN_DIR}/${ERR}.Aligned.sortedByCoord.out.bam already exists..."
    fi;
done

exit

# ran code using following commands (sed to break into smaller subsets)
sed -n '1,3p;4q' ERR_list.txt > ERR_list_rev.txt
sbatch queue_star.sh ERR_list_rev.txt
```

# Quality Control

## FastQC

```{}
export TIME='\t%E real,\t%U user,\t%S sys,\t%K amem,\t%M mmem'

spack load fastqc

/usr/bin/time for dir in `cat ERR_cancer.txt`;
  do fastqc ./${dir}/${dir}_1.fastq.gz \
  fastqc ./${dir}/${dir}_2.fastq.gz;
done
```

`4:37.39 real,   257.60 user,    21.49 sys,      0 amem, 203648 mmem`

```{}
#!/bin/bash

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --job-name="fastqc"
#SBATCH --time=24:0:00 # HH/MM/SS
#SBATCH --mem=25G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=jwh4001@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue

# Usage : fastqc.sh <ERR> <REF_DIR> <OUT_DIR>

# Check that we have our command line arguments
if [ "$#" -ne 3 ]; then
    echo "You must enter exactly 3 command line arguments: <ERR> <REF_DIR> <OUT_DIR>"
    exit
fi

# Read argument from command line
ERR=$1
REF_DIR=$2
OUT_DIR=$3

spack load fastqc

fastqc -o ${OUT_DIR} ${REF_DIR}/${ERR}.fastq.gz

exit

```

## BamQC

```{}
/softlib/apps/EL7/BamQC/bin/bamqc -o QC/ -f hg38.99.gtf.gz -g hg38_STARindex/ alignment/*.bam
```

## RSeQC

### Read Distribution

#### Interactive

```{}
wget https://sourceforge.net/projects/rseqc/files/BED/Human_Homo_sapiens/hg38_RefSeq.bed.gz/download -O hg38_RefSeq.bed.gz
gunzip $DIR/hg38_RefSeq.bed.gz

# create symbolic link to class scratch directory - did this last time so no need to repeat
#ln -s /athena/angsd/scratch/jwh4001 /home/jwh4001/angsd
RSEQC_IMAGE="/athena/angsd/scratch/simg/rseqc-3.0.1.simg"
cd ~
spack load singularity@2.6.0
BED_FILE="/home/jwh4001/angsd/jwh4001/project/hg38_RefSeq.bed"
BAM_FILE="/home/jwh4001/angsd/jwh4001/project/alignment_2/*.bam"
OUT_FILE="/home/jwh4001/angsd/jwh4001/project/QC/project.read_distribution.txt"
singularity exec $RSEQC_IMAGE read_distribution.py -r $BED_FILE -i $BAM_FILE >> $OUT_FILE
```

#### Batch Queue Script

```{}
#!/bin/bash -l

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --job-name="batch_rseqc"
#SBATCH --time=24:0:00 # HH/MM/SS
#SBATCH --mem=1G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=jwh4001@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue


# Usage: sbatch queue_rseqc.sh <ERR_list>


# Check that we have our command line arguments
if [ "$#" -ne 1 ]; then
    echo "You must enter exactly 1 command line arguments: <ERR_list>"
    exit
fi


# Read argument from command line
ERR_FILE=$1

# check to see if ERR list exist
if [[ ! -r $ERR_FILE ]]; then
    echo "ERR list does not exist. Exiting... "
    exit
else
    echo "ERR list exists..."
fi


BED_FILE="/home/jwh4001/angsd/jwh4001/project/hg38_RefSeq.bed"
BAM_DIR="/home/jwh4001/angsd/jwh4001/project/alignment"
OUT_DIR="/home/jwh4001/angsd/jwh4001/project/QC/rseqc"


# run rseqc if file doesn't already exist
for ERR in `cat $ERR_FILE`;
    do
    if [ ! -r ${OUT_DIR}/${ERR}.read_distribution.txt ]; then
        sbatch rseqc.sh ${BED_FILE} ${BAM_DIR}/${ERR}.Aligned.sortedByCoord.out.bam \
        ${OUT_DIR}/${ERR}.read_distribution.txt
    else
        echo "${OUT_DIR}/${ERR}.read_distribution.txt already exists..."
    fi;
done

exit
```

#### Read Distribution Script

```{}
#!/bin/bash

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --job-name="rseqc"
#SBATCH --time=24:0:00 # HH/MM/SS
#SBATCH --mem=25G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=jwh4001@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue

# Usage: rseqc.sh <BED_FILE> <BAM_FILE> <OUT_FILE>

# Check that we have our command line arguments
if [ "$#" -ne 3 ]; then
    echo "You must enter exactly 3 command line arguments: <BED_FILE> <BAM_FILE$
    exit
fi
# Read argument from command line
BED_FILE=$1
BAM_FILE=$2
OUT_FILE=$3


RSEQC_IMAGE="/athena/angsd/scratch/simg/rseqc-3.0.1.simg"

spack load singularity@2.6.0

singularity exec $RSEQC_IMAGE read_distribution.py -r $BED_FILE -i $BAM_FILE >> $OUT_FILE


exit
```

#### Read Distribution For Loop

```{}
# batched ~10 at a time to confirm was running properly
sed -n '2,10p;11q' ERR_cancer.txt > ERR_list_rev.txt

BED_FILE="/home/jwh4001/angsd/jwh4001/project/hg38_RefSeq.bed"
BAM_DIR="/home/jwh4001/angsd/jwh4001/project/alignment"
OUT_DIR="/home/jwh4001/angsd/jwh4001/project/QC/rseqc"

RSEQC_IMAGE="/athena/angsd/scratch/simg/rseqc-3.0.1.simg"

spack load singularity@2.6.0

for ERR in `cat ERR_list_rev.txt`; do
    singularity exec $RSEQC_IMAGE read_distribution.py -r $BED_FILE -i \
    ${BAM_DIR}/${ERR}.Aligned.sortedByCoord.out.bam >> \
    ${OUT_DIR}/${ERR}.read_distribution.txt;
done
```

### Gene Body Coverage

I initially used the 

This took so long to run that I couldn't create a single output.  While I wrote scripts to batch this process, I could not get them to run in enough time.

## MultiQC

While I was unable to complete the QC using `RSeQC`, I incorporated the results from `BamQC` and `STAR` into a `MultiQC` report that I've uploaded to my [github repository](https://github.com/jessicaw9910/ANGSD).

```{}
cd $DIR/QC/
spack load -r py-multiqc
multiqc *bamqc.zip ../alignment_2/*.Log.final.out *.flagstat.txt
cp multiqc_report.html ~

multiqc -n multiqc_report_2020.04.12.html ../alignment/*.Log.final.out flagstat/*.flagstat.txt fastqc/*.zip

# could not figure out how to incorporate BamQC reports into MultiQC
find . -type f -name '*.zip' -exec unzip -- '{}' -x '*.zip' \;
/BamQC_files
```

# featureCounts and DESeq2

## featureCounts

I used most of the `featureCounts` defaults, with the exception of `-p`, which I added, denoting that the reads are paired-end.  Note that I attempted to write a script as occassionally my connection timed out when I ran the below code, but I received an error message directing me to the `featureCounts` documentation when I ran an identical script to the below (adjusting directory location where necessary). 

```{}
mkdir read_counts

cd read_counts

var=$(date +'%y.%m.%d')

spack load subread

# create featureCounts files for the 5 files I was able to align 
featureCounts -p \ #since paired-end reads
              -T 2 \
              -a hg38.99.gtf.gz \
              -o read_counts/project_${var}.txt \
              alignment/*.bam
      
cp read_counts/project_20.03.14.* ~              
```

To download the following files and upload to my repo I used the following commands.

```{}
cp project_*.txt* ~ 
pscp jwh4001@aristotle.med.cornell.edu:/home/jwh4001/multiqc_report.html OneDrive/MS-CB/ANGSD/project
pscp jwh4001@aristotle.med.cornell.edu:/home/jwh4001/project_*.txt* OneDrive/MS-CB/ANGSD/project

cd OneDrive/MS-CB/ANGSD/project
git add .
git commit -m "updated multiqc and read count files"
git push origin master
```

## DESeq2 analysis

```{r import_data, message=FALSE}
library(magrittr)

# import read counts file and remove extraneous info in colnames
readcounts <- read.table('C:/Users/jessb/OneDrive/MS-CB/ANGSD/project/counts/project_20.04.09.txt', sep = '\t',header = TRUE)
names(readcounts) = gsub(pattern = "alignment.", replacement = "", x = names(readcounts))
names(readcounts) = gsub(pattern = ".Aligned.sortedByCoord.out.bam", replacement = "", x = names(readcounts))

# import column names in order
col_names <- read.table('C:/Users/jessb/OneDrive/MS-CB/ANGSD/project/files/col_names.txt', header = FALSE, stringsAsFactors = FALSE)
orig_names <- names(readcounts)
rownames(readcounts) <- readcounts$Geneid
colnames(readcounts) <- c(colnames(readcounts)[1:6],
                          col_names$V1)

# remove first 6 columns and create sample conditions df
readcounts <- readcounts[ , -c(1:6)]
sample_info <- data.frame(condition = c(rep("normal", 27), rep("cancer", 36)))
rownames(sample_info) <- names(readcounts)
```

Given that we observed during alignment that fewer 

```{r qc_r, message=FALSE}
library(ggplot2)
library(reshape2)

col_sums <- melt(colSums(readcounts))
condition <- c(rep("normal", 27), rep("cancer", 36))
col_sums <- cbind(col_sums, condition)
for (n in seq(1, length(readcounts))){
  col_sums$genes_expressed[n] <- sum(readcounts[, n] > 0)
}
rownames(col_sums) <- gsub("LC_", "", rownames(col_sums))

ggplot(col_sums, aes(x = value, y = genes_expressed, color = condition)) +
  geom_point() +
  geom_smooth(method = lm) +
  geom_text(label=rownames(col_sums), size=1.75, nudge_y = 150) +
  xlab("Total number of transcripts detected") +
  ylab("Number of unique genes detected")

summary(lm(genes_expressed ~ value + factor(condition), data = col_sums))
```

```{r deseq_1, message=FALSE}
library(DESeq2)
library(magrittr)

DESeq.ds <- DESeqDataSetFromMatrix(countData = readcounts,
                                   colData = sample_info,
                                   design = ~ condition)

# drop genes with no reads
keep_genes <- rowSums(counts(DESeq.ds)) > 0
DESeq.ds <- DESeq.ds[ keep_genes, ]

#rlog normalization
DESeq.rlog <- rlog(DESeq.ds, blind = TRUE)
rlog.norm.counts <- assay(DESeq.rlog)
```

```{r dim_red, message=FALSE}
library(pheatmap)
library(magrittr)

corr_coeff <- cor(rlog.norm.counts, method = "pearson")
fontsize = 10 - ncol(readcounts) / 15
as.dist(1-corr_coeff, upper = TRUE) %>% 
  as.matrix %>% 
  pheatmap(., main = "Pearson correlation", fontsize = fontsize)

as.dist(1 - corr_coeff) %>% hclust %>%
  plot( ., labels = colnames(rlog.norm.counts),
        main = "rlog transformed read counts", cex = 0.7)
```

```{r deseq_cancer, message=FALSE}
library(DESeq2)
library(magrittr)
library(ggplot2)

DESeq.ds <- DESeq(DESeq.ds)
DGE.results <- results(DESeq.ds, independentFiltering = TRUE, alpha = 0.05)

head(DGE.results)
summary(DGE.results)
table(DGE.results$padj < 0.05)
```

```{r}
# BiocManager::install("EnsDb.Hsapiens.v86")
library(EnsDb.Hsapiens.v86)

sig_genes <- order(DGE.results$padj)[1: length(which(DGE.results$padj < 0.05))]
sig_genes <- DataFrame(gene_index = sig_genes)
sig_genes$geneid <- rownames(readcounts)[sig_genes$gene_index]
sig_genes$padj <- sort(DGE.results$padj)[1: length(which(DGE.results$padj < 0.05))]

geneIDs1 <- ensembldb::select(EnsDb.Hsapiens.v86, keys = sig_genes$geneid, keytype = "GENEID", columns = c("SYMBOL","GENEID"))

sig_genes_new <- merge(sig_genes, geneIDs1, all.x = TRUE, by.x = "geneid", by.y = "GENEID")
sig_genes_new <- sig_genes_new[order(sig_genes_new$padj), ]
head(sig_genes_new)

# write.csv(sig_genes_new, "sig_genes.csv")
```

# Scripts and Code

## Downloading Data

### get_files.sh

I called the following script from the `/athena/angsd/scratch/jwh4001/project/fastq/` folder using the command `sbatch get_files.sh ERR_list.txt ftp_1.txt ftp_2.txt`.

```{}
#! / bin / bash

# Usage : get_files.sh <ERR_list> <ftp_1> <ftp_2>
# Check that we have our command line argument (s)

if [ "$#" -ne 3 ]; then
    echo "You must enter exactly 3 command line arguments"
    exit
fi

# Read argument from command line

ERR_LIST=$1
FTP_1=$2
FTP_2=$3

for recs in `cat $ERR_LIST`;
    do
    if [[ ! -f ${recs}/${recs}_1.fastq.gz ]]; then
        LINK="$(egrep ${recs} $FTP_1)"
        wget -P `pwd`/${recs}/ ftp://${LINK}
    else
        echo "${recs}/${recs}_1.fastq.gz exists"
    fi
    if [[ ! -f ${recs}/${recs}_2.fastq.gz ]]; then
        LINK="$(egrep ${recs} $FTP_2)"
        wget -P `pwd`/${recs}/ ftp://${LINK}
    else
        echo "${recs}/${recs}_2.fastq_gz exists"
    fi;
done

exit
```

## Samtools: Flagstat

### Interactive 

```{}
spack load samtools@1.9%gcc@6.3.0
cd ../alignment
for n in *.bam; do
  name="${n%.Aligned.sortedByCoord.out.bam}"
  samtools flagstat ${n} > ${name}.flagstat.txt;
done
mv *flagstat.txt ../QC/

# as a test to allow me to write a script allocating enough memory
/usr/bin/time samtools flagstat ../alignment/ERR164585.Aligned.sortedByCoord.out.bam > ../QC/flagstat/ERR164585.flagstat.txt
```

`1:27.13 real,   82.03 user,     1.92 sys,       0 amem, 3376 mmem`

This suggested that `flagstat.sh` should request 5GB of memory.

### queue_flagstat.sh

```{}
#!/bin/bash -l

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --job-name="batch_flagstat"
#SBATCH --time=24:0:00 # HH/MM/SS
#SBATCH --mem=1G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=jwh4001@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue


# Usage: sbatch queue_flagstat.sh <ERR_list>


# Check that we have our command line arguments
if [ "$#" -ne 1 ]; then
    echo "You must enter exactly 1 command line arguments: <ERR_list>"
    exit
fi


# Read argument from command line
ERR_FILE=$1

# check to see if ERR list exist
if [[ ! -r $ERR_FILE ]]; then
    echo "ERR list does not exist. Exiting... "
    exit
else
    echo "ERR list exists..."
fi


OUT_DIR=/athena/angsd/scratch/jwh4001/project/QC/flagstat


# run fastqc for first paired-end read
for ERR in `cat $ERR_FILE`;
    do
    if [ ! -r ${OUT_DIR}/${ERR}.flagstat.txt ]; then
        sbatch flagstat.sh ${ERR} ${OUT_DIR}
    else
        echo "${OUT_DIR}/${ERR}.flagstat.txt already exists..."
    fi;
done

exit
```

### flagstat.sh

```{}
#!/bin/bash

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --job-name="flagstat"
#SBATCH --time=24:0:00 # HH/MM/SS
#SBATCH --mem=5G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=jwh4001@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue

# Usage : flagstat.sh <ERR> <OUT_DIR>

# Check that we have our command line arguments
if [ "$#" -ne 2 ]; then
    echo "You must enter exactly 2 command line arguments: <ERR> <OUT_DIR>"
    exit
fi

# Read argument from command line
ERR=$1
OUT_DIR=$2

spack load samtools@1.9%gcc@6.3.0

samtools flagstat ../alignment/${ERR}.Aligned.sortedByCoord.out.bam > ${OUT_DIR}/${ERR}.flagstat.txt

echo "${OUT_DIR}/${ERR}.flagstat.txt created..."

exit
```

