---
title: "Final Project"
author: "Jess White"
date: "4/14/2020"
output: 
  html_document: 
    toc: yes
editor_options: 
  chunk_output_type: console
---

# Project work

If you need a different program than what we have used in the class, you can use `spack find` to see if the tool is already installed and loadable via spack. If your tool is not there, get in touch with scu@med.cornell.edu to ask them to install it for you.

If you have processes that will take a long time, go back to the notes from the first day and try to make use of `sbatch`.

**1. Download at least one FASTQ file that you will be working with for your project. Document the following details: (2pt)**

+ **where did you get it from?**
https://www.ebi.ac.uk/ena/data/view/ERS167310
+ **what publication is it linked to?**
[Seo et al., *Genome Research*, 2012.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3483540/pdf/2109.pdf)
+ **who generated the data?**
South Korean researchers from Seoul National University and The Catholic University of Korea
+ **how was the DNA extracted?**
RNAs were extracted from tissue using RNAiso Plus (Takara Bio Inc.), followed by purification using RNeasy MinElute (Qiagen Inc.). RNAs were assessed for quality and was quantified using an RNA 6000 Nano LabChip on a 2100 Bioanalyzer (Agilent Inc.).
+ **what library prep was used?**
All that is mentioned is that the libraries were prepared per protocol described in [Ju et al., *Nature Genetics*, 2011](https://www.nature.com/articles/ng.872).  In that paper, Illumina sequencing libraries were constructed for paired-end sequencing (with an insert size of ~500 bp) but no additional detail was provided on how the library was constructed.
+ **what cell type was used?**
Human lung cancer tumor biopsies with paired normal surrounding tissue
+ **what was the treatment/experimental condition?**
No treatment/experimental condition were used but biopsies of the tumor were matched with paired normal surrounding tissue.
+ **what sequencing platform was used?**
Illumina HiSeq 2000

**2. Align the FASTQ file with an appropriate aligner (you may have to build a new index). Document: (3pt)**

+ **parameters (and why you chose them)**
+ **summary of outcome and basic QC**

I created an index with the hg38 genome using the following commands.

```{}
wget http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz
gunzip hg38.fa.gz
wget http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/genes/hg38.ensGene.gtf.gz
gunzip hg38.ensGene.gtf.gz
mkdir hg38_STARindex

STAR -- runMode genomeGenerate \
     -- runThreadN 8 \
     -- genomeDir hg38_STARindex \ 
     -- genomeFastaFiles hg38.fa \
     -- sjdbGTFfile hg38.ensGene.gtf
```

I downloaded and organized the relevant files using the below commands.

```{}
wget -O experiment_list.txt 'https://www.ebi.ac.uk/ena/data/warehouse/filereport?accession=PRJEB2784&result=read_run&fields=study_accession,sample_accession,secondary_sample_accession,experiment_accession,run_accession,fastq_ftp&download=txt'
egrep "ERR" experiment_list.txt | cut -f 5 > ERR_list.txt
cut -f 6 experiment_list.txt | egrep "ftp" > ftp_links.txt

# create one directory per each sample and check number of folders in wd
for recs in `cat ERR_list.txt`; 
  do mkdir ${recs};
done
ls -l | grep "^d" | wc -l

# looking at the experiment_list.txt file, there are 5 run_accessions without associated FASTQ files
rmdir ERR062334 ERR062335 ERR062336 ERR062337 ERR062338

# then used text editor to remove those 5 files from the ERR_list.txt
vi ERR_list.txt

# paired end reads in separate FASTQ files
cat ftp_links.txt | grep -o "^.*;" | sed 's/.$//' > ftp_1.txt
cat ftp_links.txt | egrep ";" | sed 's/^.*;//' > ftp_2.txt

for recs in `cat ERR_list.txt`;
  do for links in `cat ftp_1.txt`;
    do wget -P `pwd`/${recs}/ ftp://${links};
  done;
done

for recs in `cat ERR_list.txt`;
  do for links in `cat ftp_2.txt`;
    do wget -P `pwd`/${recs}/ ftp://${links};
  done;
done
```

I wrote a script to run STAR aligner with paired end reads in separate FASTQ files.  I also altered some of the basic parameters, including:

 + `--outFilterMultimapNmax 20` to better align with ENCODE RNA-seq guidelines
 + `--alignSJoverhangMin 8` to better align with ENCODE RNA-seq guidelines
 + `-- alignIntronMin 10` as Luce mentioned in class, this default is considered not well chosen, so I reduced the minimum intron length to be more permissive

```{}
#! / bin / bash

# Usage : star.sh <fastq_file_1> <fastq_file_2> <genref_dir> <alignment_dir>
# Check that we have our command line argument (s)

if [ "$#" -ne 4 ]; then
    echo "You must enter exactly 2 command line arguments"
    exit
fi

# Read argument from command line
# check that necessary files and directories exist

FILE1=$1
FILE2=$2
REF_DIR=$3
ALIGN_DIR=$4

if [[ ! -f $FILE1 ]]; then
    echo "$FILE1 does not exist . Exiting ... ";
    exit
else
    echo "$FILE1 exists ..."
fi


if [[ ! -f $FILE2 ]]; then
    echo "$FILE2 does not exist . Exiting ... ";
    exit
else
    echo "$FILE2 exists ..."
fi


#check to see if reference genome directory exist
if [[ ! -d $REF_DIR ]]; then
    echo "Reference genome directory does not exist . Exiting ... "
    exit
else
    echo "Reference genome directory exists ..."
fi


#check to see if alignment output directory exist
if [[ ! -d $ALIGN_DIR ]]; then
    echo "Alignment output directory does not exist . Exiting ... "
    exit
else
    echo "Alignment output directory exists ..."
fi


# Load packages that we will need
spack load star@2.7.0e
spack load samtools@1.9% gcc@6.3.0

f1="$(basename -- $FILE1)"
F1="${f1%.fastq.gz}"

f2="$(basename -- $FILE2)"
F2="${f2%.fastq.gz}"

FCOMBO="${F1%_1}"


# Run STAR , if result not already present
if [ ! -r ${WORKING_DIRECTORY}/${F1}.Aligned.sortedByCoord.out.bam ]; then
    STAR --runMode alignReads \
         --genomeDir ${REF_DIR} \
         --readFilesIn ${FILE1} ${FILE2} \
         --readFilesCommand zcat \
         --alignIntronMin 10 \
         --outFilterMultimapNmax 20 \
         --alignSJoverhangMin 8 \
         --outFileNamePrefix ${ALIGN_DIR}/${FCOMBO}. \
         --outSAMtype BAM SortedByCoordinate
fi


# Samtools index on BAM file
if [ -r ${ALIGN_DIR}/${F1}.Aligned.sortedByCoord.out.bam ]; then
    samtools index ${ALIGN_DIR}/${F1}.Aligned.sortedByCoord.out.bam
fi

if [ -r ${ALIGN_DIR}/${F2}.Aligned.sortedByCoord.out.bam ]; then
    samtools index ${ALIGN_DIR}/${F2}.Aligned.sortedByCoord.out.bam
fi

exit
```

```{}
bash star.sh fastq/ERR164473/ERR164473_1.fastq.gz fastq/ERR164473/ERR164473_2.fastq.gz hg38_STARindex/ alignment/
cp ERR164473Aligned.sortedByCoord.out_bamqc.html /home/jwh4001/
pscp jwh4001@aristotle.med.cornell.edu:/home/jwh4001/ERR164473.star.sorted_bamqc.html OneDrive/MS-CB/ANGSD/Project
```

I chose to use STAR instead of BWA given that this is RNA-seq data that will likely contain splice sites.  This was a good decision because 86.228% of sequences were primarily aligned and 23.726% contained splice sequences.  According to the BamQC report, this data set passed the Basic Statistics, Genome Coverage, Chromosome Read Density, Soft Clip Length Distributions, Indel Frequencies, and Mapping Quality Distribution QC tests.  However, the data set seemed to fail the Insert Length Distribution test.  I'm not sure what the distribution should generally look like, but it's heavily skewed towards the lower side with the greatest frequency of insertions <1990 bp.

![Insert Length Distribution from BamQC](ERR164473_Insert Length Distribution.png)


/scratchLocal/jwh4001

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# GitHub Repo

**1. Set up a github repository where you will store all your scripts, and ideally, even your report at one point. Send us the link to the repo. If you want to set your repo to private, you will have to grant us access, i.e. Friederike (friedue), Luce (lskrbnek), Merv (mfansler).**

On github, I created an [ANGSD repo](https://github.com/jessicaw9910/ANGSD) without a `README` file.  I already had git initialized in my local ANGSD directory, so I used the following commands to link the local directory to the github repo.

```{}
cd OneDrive/MS-CB/ANGSD
git add .
git commit -m "commit with full folder"
git remote add origin https://github.com/jessicaw9910/ANGSD.git
git remote -v
git push origin master
```

# Alignment

**2. Align all your samples. Ideally use a for-loop and/or a script, i.e. automate and standardize the task to a certain extent, but do remember that legibility is valuable, too.**

My original code for downloading the relevant files did not work properly.  I re-wrote the code below and saved it as `get_files.sh`

```{}
#! / bin / bash

# Usage : get_files.sh <ERR_list> <ftp_1> <ftp_2>
# Check that we have our command line argument (s)

if [ "$#" -ne 3 ]; then
    echo "You must enter exactly 3 command line arguments"
    exit
fi

# Read argument from command line

ERR_LIST=$1
FTP_1=$2
FTP_2=$3

for recs in `cat $ERR_LIST`;
    do
    if [[ ! -f ${recs}/${recs}_1.fastq.gz ]]; then
        LINK="$(egrep ${recs} $FTP_1)"
        wget -P `pwd`/${recs}/ ftp://${LINK}
    else
        echo "${recs}/${recs}_1.fastq.gz exists"
    fi
    if [[ ! -f ${recs}/${recs}_2.fastq.gz ]]; then
        LINK="$(egrep ${recs} $FTP_2)"
        wget -P `pwd`/${recs}/ ftp://${LINK}
    else
        echo "${recs}/${recs}_2.fastq_gz exists"
    fi;
done

exit

DIR=/athena/angsd/scratch/jwh4001/project/
cd $DIR/fastq/
bash get_files.sh ERR_list.txt ftp_1.txt ftp_2.txt
```

Additionally, I had not downloaded the annotation file previously, so I did that, as well.

```{}
cd ..
wget ftp://ftp.ensembl.org/pub/release-99/gtf/homo_sapiens/Homo_sapiens.GRCh38.99.gtf.gz -O hg38.99.gtf.gz
```

Per Merv's feedback, I altered the STAR code to run a 2-pass alignment rather than a 1-pass.  To do so, I put the initial alignment output in `alignment_1` and did not output a SAM/BAM file (`--outSAMtype None`).  Then I ran STAR again with the alignment output in `alignment_2` and added the option `--sjdbFileChrStartEnd ${ALIGN_DIR_1}/${recs}.SJ.out.tab`.

Using the following partition, `srun -n 4 --pty --partition=angsd_class --mem=50G bash -i`, it took at least an hour to run each sample.  Therefore, it will take at least a week to run all 169 samples via batch queuing.  Can you please confirm that the 2-pass approach I've implemented is correct and advise if increasing memory beyond the 50G in the batch queue script would be appropriate?  I attempted to run on more than 1 thread previously, but was informed that batch queue scripts can only access 1 thread.  I have not attempted to access more than 100G of the partition for any task to date.

```{}
rm -r alignment/*
rmdir alignment
mkdir alignment_1
mkdir alignment_2

#!/bin/bash

# Usage : star.sh <ERR_file> <genref_dir> <alignment_dir_1> <alignment_dir_2>


# Check that we have our command line arguments
if [ "$#" -ne 4 ]; then
    echo "You must enter exactly 4 command line arguments: <ERR_file> <generef_dir> <alignment_dir_1> <alignment_dir_2>"
    exit
fi


# Read argument from command line
ERR_FILE=$1
REF_DIR=$2
ALIGN_DIR_1=$3
ALIGN_DIR_2=$4


# check that necessary files and directories exist
# check to see if ERR file exist
if [[ ! -r $ERR_FILE ]]; then
    echo "ERR file does not exist. Exiting..."
    exit
else
    echo "ERR file exists..."
fi

# check to see if reference genome directory exist
if [[ ! -d $REF_DIR ]]; then
    echo "Reference genome directory does not exist. Exiting... "
    exit
else
    echo "Reference genome directory exists..."
fi

# check to see if alignment output directory 1 exist
if [[ ! -d $ALIGN_DIR_1 ]]; then
    echo "Alignment output directory 1 does not exist. Exiting... "
    exit
else
    echo "Alignment output directory 1 exists..."
fi

# check to see if alignment output directory 2 exist
if [[ ! -d $ALIGN_DIR_2 ]]; then
    echo "Alignment output directory 2 does not exist. Exiting... "
    exit
else
    echo "Alignment output directory 2 exists..."
fi


# Load packages that we will need
spack load star@2.7.0e
spack load samtools@1.9% gcc@6.3.0


# for loop iterates over ERR list and runs 2-pass STAR
for recs in `cat $ERR_FILE`;
    do
    FILE1=fastq/${recs}/${recs}_1.fastq.gz
    FILE2=fastq/${recs}/${recs}_2.fastq.gz
    if [[ ! -f $FILE1 ]]; then
        echo "$FILE1 does not exist. Continuing to next entry...";
        continue
    else
        echo "$FILE1 exists..."
    fi
    if [[ ! -f $FILE2 ]]; then
        echo "$FILE2 does not exist. Continuing to next entry...";
        continue
    else
        echo "$FILE2 exists..."
    fi
    # Run 2-pass STAR, if result not already present
    if [ ! -r ${ALIGN_DIR_2}/${recs}.Aligned.sortedByCoord.out.bam ]; then
        #run first pass with files going to $ALIGN_DIR_1 and no SAM/BAM output
        STAR --runMode alignReads \
             --genomeDir ${REF_DIR} \
             --readFilesIn ${FILE1} ${FILE2} \
             --readFilesCommand zcat \
             --alignIntronMin 10 \
             --outFilterMultimapNmax 20 \
             --alignSJoverhangMin 8 \
             --outFileNamePrefix ${ALIGN_DIR_1}/${recs}. \
             --outSAMtype None
        #run second pass with files going to $ALIGN_DIR_2 using SJ.out.tab file
        STAR --runMode alignReads \
             --genomeDir ${REF_DIR} \
             --sjdbFileChrStartEnd ${ALIGN_DIR_1}/${recs}.SJ.out.tab \
             --readFilesIn ${FILE1} ${FILE2} \
             --readFilesCommand zcat \
             --alignIntronMin 10 \
             --outFilterMultimapNmax 20 \
             --alignSJoverhangMin 8 \
             --outFileNamePrefix ${ALIGN_DIR_2}/${recs}. \
             --outSAMtype BAM SortedByCoordinate
    fi
    # Samtools index on BAM file
    if [ ! -r ${ALIGN_DIR_2}/${recs}.Aligned.sortedByCoord.out.bam.bai ]; then
        samtools index ${ALIGN_DIR_2}/${recs}.Aligned.sortedByCoord.out.bam
    else
        echo "${ALIGN_DIR_2}/${recs}.Aligned.sortedByCoord.out.bam.bai already exists..."
    fi;
done

exit

bash star.sh fastq/ERR_list.txt hg38_STARindex/ alignment_1/ alignment_2/
```

```{}
DIR=/athena/angsd/scratch/jwh4001/project/
cd $DIR
rm -rf alignment_1/*
rm -rf alignment_1/*
rmdir alignment_1
rmdir_alignment_2
mkdir alignment/

mkdir scripts/
mv *.sh scripts/
cp ../fastq/ERR_list.txt scripts/
cp ../fastq/*.sh scripts/
sed -n '1,3p;4q' ERR_list.txt > ERR_list_rev.txt
```

Updated STAR alignment batch script (`STAR_updated.sh`)

```{}
#!/bin/bash -l

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --job-name="STAR_alignment"
#SBATCH --time=24:0:00 # HH/MM/SS
#SBATCH --mem=50G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=jwh4001@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue

# Usage: sbatch star_updated.sh <ERR> <genref_dir> <alignment_dir>


# Check that we have our command line arguments
if [ "$#" -ne 3 ]; then
    echo "You must enter exactly 3 command line arguments: <ERR> <generef_dir> $
    exit
fi


# Read argument from command line
ERR=$1
REF_DIR=$2
ALIGN_DIR=$3


# check to see if reference genome directory exist
if [[ ! -d $REF_DIR ]]; then
    echo "Reference genome directory does not exist. Exiting... "
    exit
else
    echo "Reference genome directory exists..."
fi


# check to see if alignment output directory exist
if [[ ! -d $ALIGN_DIR ]]; then
    echo "Alignment output directory does not exist. Exiting... "
    exit
else
    echo "Alignment output directory exists..."
fi


# Load packages that we will need
spack load star@2.7.0e
spack load samtools@1.9% gcc@6.3.0


FILE1=/athena/angsd/scratch/jwh4001/project/fastq/${ERR}/${ERR}_1.fastq.gz
FILE2=/athena/angsd/scratch/jwh4001/project/fastq/${ERR}/${ERR}_2.fastq.gz

if [[ ! -f $FILE1 ]]; then
    echo "$FILE1 does not exist. Exiting...";
    exit
else
    echo "$FILE1 exists..."
if [[ ! -f $FILE2 ]]; then
    echo "$FILE2 does not exist. Exiting...";
    exit
else
    echo "$FILE2 exists..."
fi


# Run 2-pass STAR, if result not already present
if [ ! -r ${ALIGN_DIR}/${ERR}.Aligned.sortedByCoord.out.bam ]; then
    STAR --runMode alignReads \
         --runThreadN 4 \
         --genomeDir ${REF_DIR} \
         --readFilesIn ${FILE1} ${FILE2} \
         --readFilesCommand zcat \
         --twopassMode Basic \
         --alignIntronMin 10 \
         --outFilterMultimapNmax 20 \
         --alignSJoverhangMin 8 \
         --outFileNamePrefix ${ALIGN_DIR}/${ERR}. \
         --outSAMtype BAM SortedByCoordinate
fi

# Samtools index on BAM file if index file doesn't already exist
if [ ! -r ${ALIGN_DIR}/${ERR}.Aligned.sortedByCoord.out.bam.bai ]; then
    samtools index ${ALIGN_DIR}/${ERR}.Aligned.sortedByCoord.out.bam
else
    echo "${ALIGN_DIR}/${ERR}.Aligned.sortedByCoord.out.bam.bai already exists..."
fi

exit
```

New batch script to run new STAR alignment script for all ERR entries (`queue_star.sh`)

```{}
#!/bin/bash -l

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --job-name="batch_STAR"
#SBATCH --time=24:0:00 # HH/MM/SS
#SBATCH --mem=1G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=jwh4001@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue

# Usage: sbatch queue_star.sh <ERR_list>


# Check that we have our command line arguments
if [ "$#" -ne 1 ]; then
    echo "You must enter exactly 1 command line arguments: <ERR_list>"
    exit
fi


# Read argument from command line
ERR_FILE=$1

# check to see if ERR list exists
if [[ ! -r $ERR_FILE ]]; then
    echo "ERR file does not exist. Exiting... "
    exit
else
    echo "ERR file exists..."
fi


REF_DIR=/athena/angsd/scratch/jwh4001/project/hg38_STARindex/
ALIGN_DIR=/athena/angsd/scratch/jwh4001/project/alignment/


for ERR in `cat $ERR_FILE`;
    do
    if [ ! -r ${ALIGN_DIR}/${ERR}.Aligned.sortedByCoord.out.bam ]; then
        sbatch star_updated.sh ${ERR} ${REF_DIR} ${ALIGN_DIR}
    else
        echo "${ALIGN_DIR}/${ERR}.Aligned.sortedByCoord.out.bam already exists..."
    fi;
done

exit





sed -n '1,3p;4q' ERR_list.txt > ERR_list_rev.txt
sbatch queue_star.sh ERR_list_rev.txt
```

# Read Count Table

**3. Generate a read count table.**

I used most of the `featureCounts` defaults, with the exception of `-p`, which I added, denoting that the reads are paired-end.

```{}
mkdir read_counts

spack load subread

# create featureCounts files for the 5 files I was able to align 
featureCounts -p \ #since paired-end reads
              -T 2 \
              -a hg38.99.gtf.gz \
              -o read_counts/project_20.03.14.txt \
              alignment_2/*.bam
      
cp read_counts/project_20.03.14.* ~              
```

# Read Count in R and QC

**4. Read the read count table into R and perform the quality controls and processing steps that we discussed in class.**

## Read count table

```{r}
df1 <- read.table('C:/Users/jessb/OneDrive/MS-CB/ANGSD/HW/HW8/project_20.03.14.txt', sep = '\t',header = TRUE)
names(df1) = gsub(pattern = "alignment_2.", replacement = "", x = names(df1))
names(df1) = gsub(pattern = ".Aligned.sortedByCoord.out.bam", replacement = "", x = names(df1))
head(df1)
```

## BamQC

```{}
/softlib/apps/EL7/BamQC/bin/bamqc -o QC/ -f hg38.99.gtf.gz -g hg38_STARindex/ alignment_2/*.bam
```

## RSeQC

I could not get the `read_distribution.py` script to run sufficiently quickly to submit it.  For my own future refence, an aggregate of annotated `.bed` files can be found [here](https://sourceforge.net/projects/rseqc/files/BED/Human_Homo_sapiens/).

Do you have any suggestions for getting this to run more quickly?  I've read about using GNU parallel or potentially using a BigWig package or file format to optimize.

```{}
# requires a .bed file, which ensembl doesn't create so converted gtf
spack find
spack load bedops@2.4.35
gunzip gunzip hg38.99.gtf.gz
# since missing "transcript_id" field won't pass convert2bed's internal QC; need to add
awk '{ if ($0 ~ "transcript_id") print $0; else print $0" transcript_id \"\";"; }' hg38.99.gtf > hg38.99.rev.gtf
convert2bed --input=gtf < hg38.99.rev.gtf > hg38.99.bed
rm hg38.99.rev.gtf
gzip hg38.99.gtf

# the above BED file returned errors, so I downloaded the RefSeq BED file for hg38
wget https://sourceforge.net/projects/rseqc/files/BED/Human_Homo_sapiens/hg38_RefSeq.bed.gz/download -O hg38_RefSeq.bed.gz
gunzip $DIR/hg38_RefSeq.bed.gz

# create symbolic link to class scratch directory - did this last time so no need to repeat
#ln -s /athena/angsd/scratch/jwh4001 /home/jwh4001/angsd
RSEQC_IMAGE="/athena/angsd/scratch/simg/rseqc-3.0.1.simg"
cd ~
spack load singularity@2.6.0
BED_FILE="/home/jwh4001/angsd/jwh4001/project/hg38_RefSeq.bed"
BAM_FILE="/home/jwh4001/angsd/jwh4001/project/alignment_2/*.bam"
OUT_FILE="/home/jwh4001/angsd/jwh4001/project/QC/project.read_distribution.txt"
singularity exec $RSEQC_IMAGE read_distribution.py -r $BED_FILE -i $BAM_FILE >> $OUT_FILE
```

## QoRTs

Like `RSeQC`, this tok a long time to run and generate results for these files.  Eventually, an out of memory error was thrown and in the end only log files were produced rather than the expected html output.

```{}
spack load qorts@1.2.42
QORTS_LOC=`spack location -i qorts`

cd alignment_2/

name=1

#removed --singleEnded from what we used in class given paired-end
#warning suggested I set --maxReadLength (>101 in file) in future
for bam in *.bam; do 
    java -Xmx4G -jar ${QORTS_LOC}/bin/QoRTs.jar QC /
    --generatePdfReport ${bam} ../hg38.99.gtf.gz ../QC/${name}
name=name+1;
done
```

## Samtools

```{}
spack load samtools@1.9%gcc@6.3.0
cd ../alignment_2
for n in *.bam; do
       name="${n%.Aligned.sortedByCoord.out.bam}"
       samtools flagstat ${n} > ${name}.flagstat.txt;
done
mv *flagstat.txt ../QC/
```

## MultiQC

While I was unable to complete the QC using `RSeQC`, I incorporated the results from `BamQC` and `STAR` into a `MultiQC` report that I've uploaded to my [github repository](https://github.com/jessicaw9910/ANGSD).

```{}
cd $DIR/QC/
spack load -r py-multiqc
multiqc *bamqc.html ../alignment_2/*.Log.final.out *.flagstat.txt
cp multiqc_report.html ~
```

To download the following files and upload to my repo I used the following commands.

```{}
cp project_20.03.14.txt* ~ 
pscp jwh4001@aristotle.med.cornell.edu:/home/jwh4001/multiqc_report.html OneDrive/MS-CB/ANGSD/project
pscp jwh4001@aristotle.med.cornell.edu:/home/jwh4001/project_20.03.14.txt* OneDrive/MS-CB/ANGSD/project

cd OneDrive/MS-CB/ANGSD/project
git add .
git commit -m "updated multiqc and read count files"
git push origin master
```